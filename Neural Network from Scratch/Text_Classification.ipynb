{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GB873ihFhVY"
      },
      "source": [
        "# Text Classification\n",
        "\n",
        "LSTM for Time Series Data is [here](https://colab.research.google.com/drive/1uKRCjXnUdxWFoNv298q4dNOJyfWAPHtX?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PV976JGAZWL5"
      },
      "source": [
        "Please download the file text_data.csv from https://drive.google.com/file/d/1F3Zsb6zEdu-yKyrHi3RzpCm9g3M6Vmr5/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlYsJmWW-FZ1",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!gdown --id 1F3Zsb6zEdu-yKyrHi3RzpCm9g3M6Vmr5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6scKt8F-GR2",
        "outputId": "5867c5ae-4907-44cd-e9c5-3c5d759d8499",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "punpromotion.csv    2302\n",
              "CH3Thailand.csv     1934\n",
              "ejan2016.csv         319\n",
              "Name: class, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df=pd.read_csv('text_data.csv')\n",
        "df['class'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "b8nfS3_gYfmb",
        "outputId": "39394504-0574-4f35-c1a8-fdf29ed86f6e",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f8bb44a1-de37-498d-9926-a6672554c028\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>message</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>‡∏≠‡∏¢‡πà‡∏≤ ‡πÇ‡∏Å‡∏£‡∏ò ‡πÅ‡∏°‡πà ‡∏Ç‡∏≤‡∏¢ üò≠üò≠ ‡∏î‡∏π ‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà</td>\n",
              "      <td>CH3Thailand.csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>‡πÅ‡∏≠‡∏Ñ‡∏ä‡∏±‡πà‡∏ô ‡πÄ‡∏ï‡πá‡∏° ‡πÅ‡∏ñ‡∏° ‡∏ã‡∏∂‡πâ‡∏á ‡∏â‡∏≤‡∏Å ‡∏´‡∏ß‡∏≤‡∏ô ‡∏î‡∏π ‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á ...</td>\n",
              "      <td>CH3Thailand.csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>‡∏£‡πâ‡∏≠‡∏á‡πÑ‡∏´‡πâ ‡πÑ‡∏´‡∏ß ‡∏ó‡∏î ‡∏Å‡∏•‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô ‡∏ó‡∏≤‡∏™ ‡πÄ‡∏î‡πá‡∏Å ‡∏î‡∏π ‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á ...</td>\n",
              "      <td>CH3Thailand.csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>‡∏£‡∏∑‡πâ‡∏≠ ‡∏Å‡∏£‡∏∞‡πÄ‡∏õ‡πã‡∏≤ ‡πÄ‡∏ú‡πà‡∏≤ ‡∏™‡πà‡∏≠‡∏á  ‡πÑ‡∏≠‡πÄ‡∏ó‡∏° ‡πÄ‡∏î‡πá‡∏î ‡∏î‡∏π ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° ...</td>\n",
              "      <td>CH3Thailand.csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î ‡∏ó‡∏µ‡πà‡∏à‡∏∞ ‡πÇ‡∏î‡∏ô ‡πÄ‡∏Ü‡∏µ‡πà‡∏¢‡∏ô ‡∏ó‡∏î ‡πÉ‡∏à‡πÄ‡∏î‡πá‡∏î  ‡∏î‡∏π ‡∏¢‡πâ‡∏≠‡∏ô...</td>\n",
              "      <td>CH3Thailand.csv</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8bb44a1-de37-498d-9926-a6672554c028')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f8bb44a1-de37-498d-9926-a6672554c028 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f8bb44a1-de37-498d-9926-a6672554c028');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             message            class\n",
              "0            ‡∏≠‡∏¢‡πà‡∏≤ ‡πÇ‡∏Å‡∏£‡∏ò ‡πÅ‡∏°‡πà ‡∏Ç‡∏≤‡∏¢ üò≠üò≠ ‡∏î‡∏π ‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà  CH3Thailand.csv\n",
              "1   ‡πÅ‡∏≠‡∏Ñ‡∏ä‡∏±‡πà‡∏ô ‡πÄ‡∏ï‡πá‡∏° ‡πÅ‡∏ñ‡∏° ‡∏ã‡∏∂‡πâ‡∏á ‡∏â‡∏≤‡∏Å ‡∏´‡∏ß‡∏≤‡∏ô ‡∏î‡∏π ‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á ...  CH3Thailand.csv\n",
              "2   ‡∏£‡πâ‡∏≠‡∏á‡πÑ‡∏´‡πâ ‡πÑ‡∏´‡∏ß ‡∏ó‡∏î ‡∏Å‡∏•‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô ‡∏ó‡∏≤‡∏™ ‡πÄ‡∏î‡πá‡∏Å ‡∏î‡∏π ‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á ...  CH3Thailand.csv\n",
              "3   ‡∏£‡∏∑‡πâ‡∏≠ ‡∏Å‡∏£‡∏∞‡πÄ‡∏õ‡πã‡∏≤ ‡πÄ‡∏ú‡πà‡∏≤ ‡∏™‡πà‡∏≠‡∏á  ‡πÑ‡∏≠‡πÄ‡∏ó‡∏° ‡πÄ‡∏î‡πá‡∏î ‡∏î‡∏π ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° ...  CH3Thailand.csv\n",
              "4   ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î ‡∏ó‡∏µ‡πà‡∏à‡∏∞ ‡πÇ‡∏î‡∏ô ‡πÄ‡∏Ü‡∏µ‡πà‡∏¢‡∏ô ‡∏ó‡∏î ‡πÉ‡∏à‡πÄ‡∏î‡πá‡∏î  ‡∏î‡∏π ‡∏¢‡πâ‡∏≠‡∏ô...  CH3Thailand.csv"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TXzxhJ7sHsM",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "df['word_length'] = df['message'].str.split()\n",
        "df['word_length'] = df['word_length'].str.len()\n",
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cgKyCv_yBNj",
        "outputId": "a76f1b9e-7cd8-4f10-ec67-0f4c07db040d",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2574    355.0\n",
              "4089    337.0\n",
              "2113    282.0\n",
              "2021    233.0\n",
              "1943    219.0\n",
              "        ...  \n",
              "4073      2.0\n",
              "143       2.0\n",
              "4500      2.0\n",
              "2400      2.0\n",
              "2307      2.0\n",
              "Name: word_length, Length: 4554, dtype: float64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['word_length'].sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WT2oh3kPbLTt",
        "outputId": "6d76b74a-7092-4e8a-d932-a38379b464f6",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([' ‡∏≠‡∏¢‡πà‡∏≤ ‡πÇ‡∏Å‡∏£‡∏ò ‡πÅ‡∏°‡πà ‡∏Ç‡∏≤‡∏¢ üò≠üò≠ ‡∏î‡∏π ‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà',\n",
              "       ' ‡πÅ‡∏≠‡∏Ñ‡∏ä‡∏±‡πà‡∏ô ‡πÄ‡∏ï‡πá‡∏° ‡πÅ‡∏ñ‡∏° ‡∏ã‡∏∂‡πâ‡∏á ‡∏â‡∏≤‡∏Å ‡∏´‡∏ß‡∏≤‡∏ô ‡∏î‡∏π ‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á ‡∏•‡∏¥‡∏Ç‡∏¥‡∏ï ‡∏à‡∏±‡∏ô‡∏ó‡∏£‡πå ‡∏ü‡∏±‡∏á ‡∏ô‡∏±‡∏Å‡πÅ‡∏™‡∏î‡∏á ‡πÄ‡∏•‡πà‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á ‡∏™‡∏ô‡∏∏‡∏Å ‡∏Å‡∏≠‡∏á ‡∏ñ‡πà‡∏≤‡∏¢ ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° ‡∏Å‡∏≠‡∏á ‡∏ß‡∏¥‡∏Å  ‡∏•‡∏¥‡∏Ç‡∏¥‡∏ï ‡∏à‡∏±‡∏ô‡∏ó‡∏£‡πå ‡∏ß‡∏±‡∏ô‡∏û‡∏£‡∏∏‡πà‡∏á‡∏ô‡∏µ‡πâ ‡πÄ‡∏ß‡∏•‡∏≤ 09.15 ‡∏ô. ',\n",
              "       ' ‡∏£‡πâ‡∏≠‡∏á‡πÑ‡∏´‡πâ ‡πÑ‡∏´‡∏ß ‡∏ó‡∏î ‡∏Å‡∏•‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô ‡∏ó‡∏≤‡∏™ ‡πÄ‡∏î‡πá‡∏Å ‡∏î‡∏π ‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà', ...,\n",
              "       '  ‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï ‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏î ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á ‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à ‡∏õ‡∏±‡∏ô ‡πÇ‡∏õ‡∏£ >> ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô ‡∏õ‡∏±‡∏ô ‡πÇ‡∏õ‡∏£ <<  ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà ‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏î ‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï ‡∏¢‡∏≠‡∏î ‡∏ä‡∏≥‡∏£‡∏∞‡πÄ‡∏á‡∏¥‡∏ô facebook message >> ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ‡πÅ‡∏ö‡πà‡∏á‡∏õ‡∏±‡∏ô <<  ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà Siam Paragon Siam Center Siam SQ 1, CentralWorld  ‡πÄ‡∏ß‡∏•‡∏≤ ‡∏®‡∏∏‡∏Å‡∏£‡πå ‡πÄ‡∏™‡∏≤‡∏£‡πå ‡∏≠‡∏≤‡∏ó‡∏¥‡∏ï‡∏¢‡πå ‡πÄ‡∏ß‡∏•‡∏≤ 11.00 ‡∏ô.  21.00  ‡∏ä‡∏≥‡∏£‡∏∞ ‡∏Ñ‡πà‡∏≤ ‡∏≠‡∏≤‡∏´‡∏≤‡∏£ ‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ ‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏î ‡πÄ‡∏á‡∏¥‡∏ô‡∏™‡∏î ‡∏Ñ‡πà‡∏≤‡∏ò‡∏£‡∏£‡∏°‡πÄ‡∏ô‡∏µ‡∏¢‡∏° ‡πÅ‡∏ö‡πà‡∏á‡∏õ‡∏±‡∏ô >> ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏ <<  ‡πÅ‡∏ö‡πà‡∏á‡∏õ‡∏±‡∏ô ‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏î ‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏Å ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô  ‡∏™‡∏á‡∏ß‡∏ô‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á ‡πÅ‡∏ö‡πà‡∏á‡∏õ‡∏±‡∏ô ‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏î ‡πÅ‡∏à‡πâ‡∏á‡πÉ‡∏´‡πâ‡∏ó‡∏£‡∏≤‡∏ö ‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤',\n",
              "       '  ‡πÄ‡∏ö‡∏∑‡πà‡∏≠ ‡πÑ‡∏´‡∏° ‡∏û‡∏•‡∏≤‡∏î ‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏î ‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï ‡∏õ‡∏±‡∏ô ‡πÇ‡∏õ‡∏£',\n",
              "       ' ‡πÅ‡∏ö‡πà‡∏á‡∏õ‡∏±‡∏ô ‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏î ‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ä‡∏±‡πà‡∏ô ‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï ‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£ ‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏î ‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤ ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà ‡πÅ‡∏ö‡πà‡∏á‡∏õ‡∏±‡∏ô ‡∏£‡∏≤‡∏¢‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà ‡∏Ñ‡πà‡∏≤‡∏ò‡∏£‡∏£‡∏°‡πÄ‡∏ô‡∏µ‡∏¢‡∏° ‡πÅ‡∏ö‡πà‡∏á‡∏õ‡∏±‡∏ô ^^'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.message.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vL958ksq0SKo",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import SpatialDropout1D\n",
        "\n",
        "MAX_WORDS = 2500\n",
        "MAX_SEQUENCE_LENGTH = 355\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~')\n",
        "tokenizer.fit_on_texts(df.message.values)\n",
        "word_index = tokenizer.word_index\n",
        "X = tokenizer.texts_to_sequences(df.message.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nQMQ8ZRtzy94",
        "outputId": "d517e6c4-5f5a-43d7-86eb-5d74a10e312c",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' ‡∏≠‡∏¢‡πà‡∏≤ ‡πÇ‡∏Å‡∏£‡∏ò ‡πÅ‡∏°‡πà ‡∏Ç‡∏≤‡∏¢ üò≠üò≠ ‡∏î‡∏π ‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.message.values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zp9Ys7E0zIoD",
        "outputId": "99612e9b-3cee-42af-d1af-b9024a405f50",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[52, 2129, 115, 108, 401, 1, 22, 102]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFstpYy6ht9n",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "Y = pd.get_dummies(df['class']).values\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.10, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYebmTSqfCjZ",
        "outputId": "f4520f20-78c7-4cfc-ab4c-598f0124965d",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "58/58 [==============================] - 105s 2s/step - loss: 0.4391 - accuracy: 0.8777 - val_loss: 0.0832 - val_accuracy: 0.9854\n",
            "Epoch 2/5\n",
            "58/58 [==============================] - 96s 2s/step - loss: 0.0553 - accuracy: 0.9832 - val_loss: 0.0444 - val_accuracy: 0.9854\n",
            "Epoch 3/5\n",
            "58/58 [==============================] - 90s 2s/step - loss: 0.0938 - accuracy: 0.9751 - val_loss: 0.0516 - val_accuracy: 0.9829\n",
            "Epoch 4/5\n",
            "58/58 [==============================] - 89s 2s/step - loss: 0.0294 - accuracy: 0.9908 - val_loss: 0.0410 - val_accuracy: 0.9902\n",
            "Epoch 5/5\n",
            "58/58 [==============================] - 89s 2s/step - loss: 0.0170 - accuracy: 0.9957 - val_loss: 0.0411 - val_accuracy: 0.9902\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_DIM, input_length=X_train.shape[1]))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "epochs = 5\n",
        "batch_size = 64\n",
        "\n",
        "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJcqo64i8fcN",
        "outputId": "e63ed28e-06c7-49ed-b4c4-5ba56759380e",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 2s 120ms/step - loss: 0.0611 - accuracy: 0.9781\n",
            "Test set\n",
            "  Loss: 0.061\n",
            "  Accuracy: 0.978\n"
          ]
        }
      ],
      "source": [
        "acc = model.evaluate(X_test, Y_test)\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(acc[0], acc[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bfkc58MeDwea",
        "outputId": "f8e3254b-2694-48e1-db87-14b349615410",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 638ms/step\n"
          ]
        }
      ],
      "source": [
        "posts = ['‡πÄ‡∏ä‡∏¥‡∏ç ‡∏î‡∏π ‡∏•‡∏∞‡∏Ñ‡∏£ ‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡∏ó‡∏∏‡πà‡∏°', '‡∏≠‡∏¢‡πà‡∏≤ ‡∏û‡∏•‡∏≤‡∏î ‡∏≠‡∏≤‡∏´‡∏≤‡∏£ ‡πÄ‡∏î‡πá‡∏î ‡∏£‡∏≤‡∏Ñ‡∏≤ ‡πÇ‡∏î‡∏ô']\n",
        "X_new_test = tokenizer.texts_to_sequences(posts)\n",
        "X_new_test = pad_sequences(X_new_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "results = model.predict(X_new_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4dI2mdYEZ9Y",
        "outputId": "a4252095-6d65-418e-bc1d-fc82d8ca805c",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[9.9806744e-01, 8.2780462e-04, 1.1047603e-03],\n",
              "       [1.7661239e-01, 1.4656284e-01, 6.7682475e-01]], dtype=float32)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gwtkdyhEg8U",
        "outputId": "6b4fb23f-1ce8-41ad-da07-3b52223e2484",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['CH3Thailand.csv', 'ejan2016.csv', 'punpromotion.csv'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['class'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cRoX1v_FcHr"
      },
      "source": [
        "# Word Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HS1aOb1M7Of",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('text_data.csv')\n",
        "df.dropna(inplace=True)\n",
        "df['word_length'] = df['message'].str.split()\n",
        "df['word_length'] = df['word_length'].str.len()\n",
        "df = df[df['word_length'] > 3]\n",
        "df = df[df['class'] == 'CH3Thailand.csv']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ar6LcFMvFbwA",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import SpatialDropout1D\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "MAX_WORDS = 10000\n",
        "MAX_SEQUENCE_LENGTH = 355\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~')\n",
        "tokenizer.fit_on_texts(df.message.values)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "X = tokenizer.texts_to_sequences(df.message.values)\n",
        "\n",
        "X_train = []\n",
        "Y_train = []\n",
        "\n",
        "for x in X:\n",
        "    for i in range(len(x) - 3):\n",
        "        X_train.append(x[i:i + 3])\n",
        "        Y_train.append(x[i + 3])\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "Y_train = to_categorical(Y_train, num_classes=MAX_WORDS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYdG1hPQFoRP",
        "outputId": "d099c224-dbac-46b3-f6e2-aaa229ceea07",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 114,  615,   34],\n",
              "       [ 615,   34,  616],\n",
              "       [  34,  616,   71],\n",
              "       ...,\n",
              "       [   3,   26,    2],\n",
              "       [  26,    2,   17],\n",
              "       [   2,   17, 1585]])"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9Om3gSJgwqX",
        "outputId": "6e2eb0f1-980d-441d-c7dd-0da595f844ba",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6aMxgmpOqCn",
        "outputId": "17992f98-323c-4345-a186-be7a99e7b94d",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "309/309 [==============================] - 23s 63ms/step - loss: 7.2951 - accuracy: 0.0376 - val_loss: 7.6792 - val_accuracy: 0.0330\n",
            "Epoch 2/50\n",
            "309/309 [==============================] - 9s 30ms/step - loss: 6.3830 - accuracy: 0.0479 - val_loss: 7.6688 - val_accuracy: 0.0330\n",
            "Epoch 3/50\n",
            "309/309 [==============================] - 7s 24ms/step - loss: 6.2624 - accuracy: 0.0479 - val_loss: 7.7175 - val_accuracy: 0.0330\n",
            "Epoch 4/50\n",
            "309/309 [==============================] - 8s 27ms/step - loss: 6.1855 - accuracy: 0.0479 - val_loss: 7.7724 - val_accuracy: 0.0330\n",
            "Epoch 5/50\n",
            "309/309 [==============================] - 8s 26ms/step - loss: 6.0956 - accuracy: 0.0479 - val_loss: 7.8291 - val_accuracy: 0.0330\n",
            "Epoch 6/50\n",
            "309/309 [==============================] - 7s 24ms/step - loss: 6.0058 - accuracy: 0.0478 - val_loss: 7.8625 - val_accuracy: 0.0327\n",
            "Epoch 7/50\n",
            "309/309 [==============================] - 8s 27ms/step - loss: 5.9216 - accuracy: 0.0472 - val_loss: 7.9264 - val_accuracy: 0.0338\n",
            "Epoch 8/50\n",
            "309/309 [==============================] - 7s 23ms/step - loss: 5.8357 - accuracy: 0.0496 - val_loss: 7.9790 - val_accuracy: 0.0356\n",
            "Epoch 9/50\n",
            "309/309 [==============================] - 8s 26ms/step - loss: 5.7406 - accuracy: 0.0657 - val_loss: 8.0147 - val_accuracy: 0.0350\n",
            "Epoch 10/50\n",
            "309/309 [==============================] - 8s 26ms/step - loss: 5.6441 - accuracy: 0.0777 - val_loss: 8.0343 - val_accuracy: 0.0403\n",
            "Epoch 11/50\n",
            "309/309 [==============================] - 7s 21ms/step - loss: 5.5501 - accuracy: 0.0865 - val_loss: 8.1071 - val_accuracy: 0.0411\n",
            "Epoch 12/50\n",
            "309/309 [==============================] - 8s 26ms/step - loss: 5.4605 - accuracy: 0.1025 - val_loss: 8.1227 - val_accuracy: 0.0423\n",
            "Epoch 13/50\n",
            "309/309 [==============================] - 8s 26ms/step - loss: 5.3737 - accuracy: 0.1130 - val_loss: 8.1867 - val_accuracy: 0.0420\n",
            "Epoch 14/50\n",
            "309/309 [==============================] - 8s 27ms/step - loss: 5.2911 - accuracy: 0.1235 - val_loss: 8.2211 - val_accuracy: 0.0461\n",
            "Epoch 15/50\n",
            "309/309 [==============================] - 9s 30ms/step - loss: 5.2121 - accuracy: 0.1362 - val_loss: 8.2359 - val_accuracy: 0.0441\n",
            "Epoch 16/50\n",
            "309/309 [==============================] - 9s 29ms/step - loss: 5.1322 - accuracy: 0.1582 - val_loss: 8.3197 - val_accuracy: 0.0505\n",
            "Epoch 17/50\n",
            "309/309 [==============================] - 7s 23ms/step - loss: 5.0571 - accuracy: 0.1696 - val_loss: 8.3368 - val_accuracy: 0.0519\n",
            "Epoch 18/50\n",
            "309/309 [==============================] - 8s 27ms/step - loss: 4.9810 - accuracy: 0.1729 - val_loss: 8.3525 - val_accuracy: 0.0484\n",
            "Epoch 19/50\n",
            "309/309 [==============================] - 8s 26ms/step - loss: 4.9115 - accuracy: 0.1860 - val_loss: 8.4167 - val_accuracy: 0.0633\n",
            "Epoch 20/50\n",
            "309/309 [==============================] - 7s 23ms/step - loss: 4.8450 - accuracy: 0.1954 - val_loss: 8.4044 - val_accuracy: 0.0659\n",
            "Epoch 21/50\n",
            "309/309 [==============================] - 9s 30ms/step - loss: 4.7796 - accuracy: 0.2045 - val_loss: 8.4426 - val_accuracy: 0.0549\n",
            "Epoch 22/50\n",
            "309/309 [==============================] - 8s 26ms/step - loss: 4.7171 - accuracy: 0.2163 - val_loss: 8.4601 - val_accuracy: 0.0619\n",
            "Epoch 23/50\n",
            "309/309 [==============================] - 7s 22ms/step - loss: 4.6533 - accuracy: 0.2300 - val_loss: 8.5564 - val_accuracy: 0.0581\n",
            "Epoch 24/50\n",
            "309/309 [==============================] - 8s 26ms/step - loss: 4.5947 - accuracy: 0.2384 - val_loss: 8.5643 - val_accuracy: 0.0654\n",
            "Epoch 25/50\n",
            "309/309 [==============================] - 7s 22ms/step - loss: 4.5372 - accuracy: 0.2457 - val_loss: 8.6147 - val_accuracy: 0.0668\n",
            "Epoch 26/50\n",
            "309/309 [==============================] - 8s 26ms/step - loss: 4.4800 - accuracy: 0.2515 - val_loss: 8.6617 - val_accuracy: 0.0654\n",
            "Epoch 27/50\n",
            "309/309 [==============================] - 8s 26ms/step - loss: 4.4280 - accuracy: 0.2559 - val_loss: 8.7182 - val_accuracy: 0.0639\n",
            "Epoch 28/50\n",
            "309/309 [==============================] - 6s 21ms/step - loss: 4.3754 - accuracy: 0.2583 - val_loss: 8.7447 - val_accuracy: 0.0572\n",
            "Epoch 29/50\n",
            "309/309 [==============================] - 8s 25ms/step - loss: 4.3250 - accuracy: 0.2631 - val_loss: 8.8329 - val_accuracy: 0.0689\n",
            "Epoch 30/50\n",
            "309/309 [==============================] - 7s 21ms/step - loss: 4.2764 - accuracy: 0.2690 - val_loss: 8.8383 - val_accuracy: 0.0686\n",
            "Epoch 31/50\n",
            "309/309 [==============================] - 8s 26ms/step - loss: 4.2282 - accuracy: 0.2739 - val_loss: 8.8713 - val_accuracy: 0.0686\n",
            "Epoch 32/50\n",
            "309/309 [==============================] - 8s 25ms/step - loss: 4.1808 - accuracy: 0.2739 - val_loss: 8.9467 - val_accuracy: 0.0651\n",
            "Epoch 33/50\n",
            "309/309 [==============================] - 7s 22ms/step - loss: 4.1362 - accuracy: 0.2791 - val_loss: 9.0061 - val_accuracy: 0.0639\n",
            "Epoch 34/50\n",
            "309/309 [==============================] - 8s 25ms/step - loss: 4.0918 - accuracy: 0.2833 - val_loss: 9.0656 - val_accuracy: 0.0636\n",
            "Epoch 35/50\n",
            "309/309 [==============================] - 7s 21ms/step - loss: 4.0448 - accuracy: 0.2879 - val_loss: 9.1220 - val_accuracy: 0.0724\n",
            "Epoch 36/50\n",
            "309/309 [==============================] - 8s 25ms/step - loss: 4.0031 - accuracy: 0.2920 - val_loss: 9.1530 - val_accuracy: 0.0724\n",
            "Epoch 37/50\n",
            "309/309 [==============================] - 7s 24ms/step - loss: 3.9592 - accuracy: 0.2955 - val_loss: 9.2236 - val_accuracy: 0.0902\n",
            "Epoch 38/50\n",
            "309/309 [==============================] - 6s 21ms/step - loss: 3.9216 - accuracy: 0.2980 - val_loss: 9.3074 - val_accuracy: 0.0878\n",
            "Epoch 39/50\n",
            "309/309 [==============================] - 8s 24ms/step - loss: 3.8818 - accuracy: 0.3011 - val_loss: 9.3100 - val_accuracy: 0.0814\n",
            "Epoch 40/50\n",
            "309/309 [==============================] - 6s 20ms/step - loss: 3.8406 - accuracy: 0.3039 - val_loss: 9.3401 - val_accuracy: 0.0823\n",
            "Epoch 41/50\n",
            "309/309 [==============================] - 7s 24ms/step - loss: 3.7986 - accuracy: 0.3074 - val_loss: 9.3868 - val_accuracy: 0.0832\n",
            "Epoch 42/50\n",
            "309/309 [==============================] - 7s 21ms/step - loss: 3.7569 - accuracy: 0.3130 - val_loss: 9.4168 - val_accuracy: 0.0837\n",
            "Epoch 43/50\n",
            "309/309 [==============================] - 7s 24ms/step - loss: 3.7198 - accuracy: 0.3167 - val_loss: 9.4759 - val_accuracy: 0.0937\n",
            "Epoch 44/50\n",
            "309/309 [==============================] - 7s 24ms/step - loss: 3.6799 - accuracy: 0.3259 - val_loss: 9.5279 - val_accuracy: 0.1185\n",
            "Epoch 45/50\n",
            "309/309 [==============================] - 7s 21ms/step - loss: 3.6410 - accuracy: 0.3322 - val_loss: 9.5796 - val_accuracy: 0.1164\n",
            "Epoch 46/50\n",
            "309/309 [==============================] - 8s 25ms/step - loss: 3.5996 - accuracy: 0.3413 - val_loss: 9.7038 - val_accuracy: 0.1208\n",
            "Epoch 47/50\n",
            "309/309 [==============================] - 7s 22ms/step - loss: 3.5610 - accuracy: 0.3466 - val_loss: 9.7179 - val_accuracy: 0.1214\n",
            "Epoch 48/50\n",
            "309/309 [==============================] - 8s 26ms/step - loss: 3.5168 - accuracy: 0.3552 - val_loss: 9.7694 - val_accuracy: 0.1307\n",
            "Epoch 49/50\n",
            "309/309 [==============================] - 6s 21ms/step - loss: 3.4818 - accuracy: 0.3617 - val_loss: 9.7893 - val_accuracy: 0.1255\n",
            "Epoch 50/50\n",
            "309/309 [==============================] - 8s 25ms/step - loss: 3.4369 - accuracy: 0.3672 - val_loss: 9.8370 - val_accuracy: 0.1331\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_DIM, input_length=X_train.shape[1]))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(300, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(20, activation='sigmoid'))\n",
        "model.add(Dense(MAX_WORDS, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 100\n",
        "\n",
        "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmHZPWHyvHsV",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def gen_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
        "    output_text = []\n",
        "    input_text = seed_text\n",
        "\n",
        "    for _ in range(num_gen_words):\n",
        "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
        "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
        "\n",
        "        # pred_word_ind = model.predict_classes(pad_encoded,verbose=0)[0]\n",
        "        predict_x = model.predict(pad_encoded, verbose=0)\n",
        "        pred_word_ind = np.argmax(predict_x, axis=1)[0]\n",
        "        pred_word = tokenizer.index_word[pred_word_ind]\n",
        "        input_text += ' ' + pred_word\n",
        "        output_text.append(pred_word)\n",
        "\n",
        "    return ' '.join(output_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xw-oQ_tLetLE",
        "outputId": "cd02fdfa-3fe0-40c7-fe4f-ab50d13bf597",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                 ‡∏≠‡∏¢‡πà‡∏≤ ‡πÇ‡∏Å‡∏£‡∏ò ‡πÅ‡∏°‡πà ‡∏Ç‡∏≤‡∏¢ üò≠üò≠ ‡∏î‡∏π ‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà\n",
              "1        ‡πÅ‡∏≠‡∏Ñ‡∏ä‡∏±‡πà‡∏ô ‡πÄ‡∏ï‡πá‡∏° ‡πÅ‡∏ñ‡∏° ‡∏ã‡∏∂‡πâ‡∏á ‡∏â‡∏≤‡∏Å ‡∏´‡∏ß‡∏≤‡∏ô ‡∏î‡∏π ‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á ...\n",
              "2        ‡∏£‡πâ‡∏≠‡∏á‡πÑ‡∏´‡πâ ‡πÑ‡∏´‡∏ß ‡∏ó‡∏î ‡∏Å‡∏•‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô ‡∏ó‡∏≤‡∏™ ‡πÄ‡∏î‡πá‡∏Å ‡∏î‡∏π ‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á ...\n",
              "3        ‡∏£‡∏∑‡πâ‡∏≠ ‡∏Å‡∏£‡∏∞‡πÄ‡∏õ‡πã‡∏≤ ‡πÄ‡∏ú‡πà‡∏≤ ‡∏™‡πà‡∏≠‡∏á  ‡πÑ‡∏≠‡πÄ‡∏ó‡∏° ‡πÄ‡∏î‡πá‡∏î ‡∏î‡∏π ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° ...\n",
              "4        ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î ‡∏ó‡∏µ‡πà‡∏à‡∏∞ ‡πÇ‡∏î‡∏ô ‡πÄ‡∏Ü‡∏µ‡πà‡∏¢‡∏ô ‡∏ó‡∏î ‡πÉ‡∏à‡πÄ‡∏î‡πá‡∏î  ‡∏î‡∏π ‡∏¢‡πâ‡∏≠‡∏ô...\n",
              "                              ...                        \n",
              "1929     ‡∏û‡∏£‡∏∏‡πà‡∏á‡∏ô‡∏µ‡πâ ‡πÅ‡∏ô‡πà ‡∏ï‡∏≠‡∏ô‡πÅ‡∏£‡∏Å ‡∏™‡∏ô‡∏∏‡∏Å ‡∏Å‡∏Å ‡∏Å‡∏Å ‡∏ä‡∏° ‡∏î‡∏π  ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á ...\n",
              "1930     ‡∏¢‡∏∏‡∏ö ‡∏û‡∏≠‡∏á ‡∏´‡∏ô‡∏≠‡∏á ‡∏¢‡∏∏‡∏ö ‡∏û‡∏≠‡∏á ‡∏ã‡∏¥‡∏Å ‡πÅ‡∏û ‡πÅ‡∏ô‡πà‡∏ô ‡∏≠‡∏≤ ‡∏ò‡∏µ‡∏£ ‡πÄ‡∏î‡∏ä  ...\n",
              "1931                                      ‡πÇ‡∏¢ ‡∏Å‡∏≤‡∏ù‡∏≤‡∏Å ‡∏î‡∏π ‡∏ï‡∏≠‡∏ô\n",
              "1932         ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ ‡∏ô‡∏±‡∏Å‡πÅ‡∏™‡∏î‡∏á ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á ‡πÇ‡∏ô‡πà ‡∏ä‡∏≤  ‡∏ä‡∏≤ ‡πÇ‡∏ô‡πà ‡πÄ‡∏•‡πà‡∏ô ‡πÄ‡∏≠‡∏≠\n",
              "1933      ‡πÑ‡∏î‡πâ‡πÄ‡∏ß‡∏•‡∏≤ ‡∏ï‡∏≤‡∏°‡∏´‡∏≤ ‡∏£‡∏±‡∏Å‡πÅ‡∏ó‡πâ  ‡∏ó‡∏±‡∏ô‡∏ï‡πÅ‡∏û‡∏ó‡∏¢‡πå ‡∏´‡∏ô‡∏∏‡πà‡∏° ‡∏´‡∏•‡πà‡∏≠ ‡∏£...\n",
              "Name: message, Length: 1930, dtype: object"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['message']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I43r7Rz_vT2S",
        "outputId": "1cd957b6-120f-4a4a-f9dd-7077f317a078",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output: ‡πÅ‡∏≠‡∏Ñ‡∏ä‡∏±‡πà‡∏ô ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î ‡πÇ‡∏î‡∏ô ‡∏™‡∏≤‡∏ò‡∏≤‡∏£‡∏ì‡∏∞ ‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô ‡∏•‡∏∞‡∏Ñ‡∏£ ‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á 62 ep ‡∏•‡∏¥‡πâ‡∏á‡∏Ñ‡πå ‡∏£‡∏±‡∏Å ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà ‡∏ï‡∏≠‡∏ô‡πÅ‡∏£‡∏Å\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"‡πÅ‡∏≠‡∏Ñ‡∏ä‡∏±‡πà‡∏ô ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î ‡πÇ‡∏î‡∏ô\"\n",
        "output = gen_text(model, tokenizer, seq_len=3, seed_text=seed_text, num_gen_words=10)\n",
        "print(f'Output: {seed_text} {output}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
